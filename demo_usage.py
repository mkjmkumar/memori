#!/usr/bin/env python3
"""
Memori Usage Demo
Simple demonstration of how Memori works with your current setup
"""

import sys
import os
from pathlib import Path

# Add memori to path
sys.path.insert(0, str(Path(__file__).parent))

def demo_basic_usage():
    """Demonstrate basic Memori usage"""
    print("üöÄ Memori Basic Usage Demo")
    print("=" * 50)

    try:
        # Import Memori
        from memori import Memori
        from litellm import completion

        print("‚úÖ Imports successful")

        # Initialize with your configuration
        memori = Memori()  # Uses memori.json configuration
        memori.enable()

        print("‚úÖ Memori initialized and enabled")

        # Show current configuration
        print("‚úÖ Using configuration from memori.json")
        print("‚úÖ Database: PostgreSQL")
        print("‚úÖ Model: GPT-4o")
        print("‚úÖ Memory namespace: demo")
        print("‚úÖ Context injection: enabled")

        # Test basic conversation
        print("\n" + "=" * 30)
        print("üß™ Testing Basic Memory Recording")
        print("=" * 30)

        # Conversation 1: Establish context
        print("\nüìù Conversation 1: Establishing Context")
        print("User: I'm a Python developer working on AI applications. I prefer FastAPI and PostgreSQL.")

        response1 = completion(
            model="gpt-4o",
            messages=[{
                "role": "user",
                "content": "I'm a Python developer working on AI applications. I prefer FastAPI and PostgreSQL."
            }]
        )

        print(f"Assistant: {response1.choices[0].message.content[:100]}...")

        # Conversation 2: Test memory recall
        print("\nüìù Conversation 2: Testing Memory Recall")
        print("User: What framework should I use for my next web API project?")

        response2 = completion(
            model="gpt-4o",
            messages=[{
                "role": "user",
                "content": "What framework should I use for my next web API project?"
            }]
        )

        print(f"Assistant: {response2.choices[0].message.content[:100]}...")

        # Conversation 3: More specific context
        print("\nüìù Conversation 3: Testing Deeper Context")
        print("User: I'm working on a real-time chat application. What's the best database for that?")

        response3 = completion(
            model="gpt-4o",
            messages=[{
                "role": "user",
                "content": "I'm working on a real-time chat application. What's the best database for that?"
            }]
        )

        print(f"Assistant: {response3.choices[0].message.content[:100]}...")

        # Show memory statistics
        print("\n" + "=" * 30)
        print("üìä Memory Statistics")
        print("=" * 30)

        try:
            stats = memori.get_memory_stats()
            print(f"Total conversations: {stats.get('total_conversations', 0)}")
            print(f"Total memories: {stats.get('total_memories', 0)}")
            print(f"Short-term memories: {stats.get('short_term_memories', 0)}")
            print(f"Long-term memories: {stats.get('long_term_memories', 0)}")
        except Exception as e:
            print(f"Could not get stats: {e}")

        # Test context retrieval
        print("\n" + "=" * 30)
        print("üîç Testing Context Retrieval")
        print("=" * 30)

        try:
            context = memori.retrieve_context("Python FastAPI", limit=3)
            print(f"Retrieved {len(context)} memories for 'Python FastAPI'")

            for i, memory in enumerate(context, 1):
                print(f"{i}. {memory.get('summary', 'No summary')}")
        except Exception as e:
            print(f"Could not retrieve context: {e}")

        print("\n" + "=" * 50)
        print("üéâ Demo completed successfully!")
        print("=" * 50)
        print("\nüìã What happened:")
        print("‚úÖ Memori automatically recorded all 3 conversations")
        print("‚úÖ AI agents processed and categorized the content")
        print("‚úÖ Memories were stored in PostgreSQL database")
        print("‚úÖ Context was intelligently retrieved and injected")
        print("‚úÖ No manual memory management required")

        return True

    except Exception as e:
        print(f"‚ùå Demo failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def demo_memory_tools():
    """Demonstrate memory tools for function calling"""
    print("\nüõ†Ô∏è Memory Tools Demo")
    print("=" * 30)

    try:
        from memori import Memori, create_memory_tool

        memori = Memori()
        memori.enable()

        # Create memory tool
        memory_tool = create_memory_tool(memori)

        print("‚úÖ Memory tool created")

        # Test tool execution
        result = memory_tool.execute(query="Python development")
        print(f"‚úÖ Tool executed: {type(result)}")

        return True

    except Exception as e:
        print(f"‚ùå Memory tools demo failed: {e}")
        return False

def main():
    """Run all demos"""
    print("üöÄ Memori Complete Demo")
    print("=" * 50)
    print("This demo shows how your Memori setup works!")
    print("=" * 50)

    # Check if virtual environment is active
    if 'memori_env' not in str(Path(sys.executable)):
        print("‚ö†Ô∏è Please activate virtual environment first:")
        print("source memori_env/bin/activate")
        return False

    # Run basic demo
    success = demo_basic_usage()

    # Run memory tools demo
    success &= demo_memory_tools()

    if success:
        print("\nüéâ All demos completed successfully!")
        print("\nüìö Next steps:")
        print("1. Use any LLM in your applications - Memori works automatically")
        print("2. Check the database for stored memories")
        print("3. Read the usage guide: mike/memori_usage_guide.md")
        print("4. Start building AI applications with intelligent memory!")

        print("\nüí° Key benefits you're now getting:")
        print("‚Ä¢ Automatic conversation recording and processing")
        print("‚Ä¢ Intelligent context injection")
        print("‚Ä¢ Universal LLM support")
        print("‚Ä¢ Persistent memory across sessions")
        print("‚Ä¢ Production-ready architecture")
    else:
        print("\n‚ùå Some demos failed. Check the errors above.")

    return success

if __name__ == "__main__":
    main()
